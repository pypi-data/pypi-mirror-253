{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload all modules (except those excluded by %aimport) every time before executing the Python code typed.\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from time import perf_counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pnstyler.styler as styler\n",
    "import ml_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = ml_confs.from_dict({\n",
    "    'train_samples': 10000,\n",
    "    'test_samples': 100,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://realpython.com/python-timer/#creating-a-python-timer-decorator\n",
    "def timer(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_timer(*args, **kwargs):\n",
    "        tic = perf_counter()\n",
    "        value = func(*args, **kwargs)\n",
    "        toc = perf_counter()\n",
    "        elapsed_time = toc - tic\n",
    "        return value, elapsed_time\n",
    "\n",
    "    return wrapper_timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kooplearn.datasets import Lorenz63, LogisticMap\n",
    "\n",
    "raw_data = Lorenz63().sample(X0 = np.ones(3), T=configs.train_samples + 1000 + configs.test_samples)\n",
    "#raw_data = LogisticMap(N=20).sample(X0 = np.ones(1), T=configs.train_samples + 1000 + configs.test_samples)\n",
    "mean = np.mean(raw_data, axis=0)\n",
    "norm = np.max(np.abs(raw_data), axis=0)\n",
    "# Data rescaling\n",
    "data = raw_data - mean\n",
    "data /= norm\n",
    "\n",
    "train_data = data[:configs.train_samples + 1]\n",
    "test_data =  data[-configs.test_samples - 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from scipy.spatial.distance import pdist\n",
    "from kooplearn.models import KernelDMD\n",
    "from kooplearn.models import NystroemKernel\n",
    "from kooplearn.data import traj_to_contexts\n",
    "\n",
    "# Length scale of the kernel: median of the pairwise distances of the dataset\n",
    "data_pdist = pdist(train_data)\n",
    "kernel = RBF(length_scale=np.quantile(data_pdist, 0.5))\n",
    "train_contexts = traj_to_contexts(train_data)\n",
    "test_contexts = traj_to_contexts(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runner(models, stop):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        print(f'{name}')\n",
    "        model, fit_time = timer(model.fit)(train_contexts[:stop], verbose=False)\n",
    "        # One-step prediction\n",
    "        X_pred = model.predict(test_contexts[:, :-1, ...])\n",
    "        X_true = test_contexts[:, 1, ...]\n",
    "        # Eigenvalues\n",
    "        eigs = model.eig()\n",
    "\n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'fit_time': fit_time,\n",
    "            'train_risk': model.risk(),\n",
    "            'rMSE_onestep': np.sqrt(np.mean((X_pred - X_true)**2)),\n",
    "            'eigenvalues': eigs,\n",
    "        }\n",
    "    return results\n",
    "    \n",
    "def hausdorff_distance(eigs_1, eigs_2):\n",
    "    dist = np.abs(eigs_1[:, None] - eigs_2[None, :])\n",
    "    d1 = np.min(dist, axis=1).max()\n",
    "    d2 = np.min(dist, axis=0).max()\n",
    "    return max(d1, d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_rank = True\n",
    "rank = 25\n",
    "num_centers = 250\n",
    "tikhonov_reg = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stops = np.logspace(3, 4, 10).astype(int)\n",
    "results = []\n",
    "for stop in train_stops:\n",
    "    models = {\n",
    "        'KernelDMD': KernelDMD(kernel=kernel, reduced_rank=reduced_rank, tikhonov_reg=tikhonov_reg, rank = rank, svd_solver='arnoldi'),\n",
    "        'RandSVDKernelDMD': KernelDMD(kernel=kernel, reduced_rank=reduced_rank, svd_solver='randomized', tikhonov_reg=tikhonov_reg, rank = rank, rng_seed=5),\n",
    "        'Nystroem': NystroemKernel(kernel=kernel, reduced_rank=reduced_rank, svd_solver='arnoldi', tikhonov_reg=tikhonov_reg, rank = rank, num_centers=num_centers, rng_seed=42),\n",
    "    }\n",
    "    print(f'\\n\\nTraining points: {stop}')\n",
    "    results.append(runner(models, stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timings = {name: [res[name]['fit_time'] for res in results] for name in models.keys()}\n",
    "rMSE = {name: [res[name]['rMSE_onestep'] for res in results] for name in models.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styler.set_color_palette('categorical_dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=styler.figsize(width_to_height=3), dpi=144)\n",
    "for name in models.keys():\n",
    "    axes[0].plot(train_stops, rMSE[name], '.-', label=name)\n",
    "    axes[1].plot(train_stops, timings[name], '.-', label=name)\n",
    "\n",
    "axes[0].set_title('rMSE')\n",
    "axes[1].set_title('Training time (s)')\n",
    "axes[1].legend(frameon = False, loc = 'upper left')\n",
    "axes[1].set_yscale('log')\n",
    "for ax in axes:\n",
    "    ax.set_xscale('log')\n",
    "    \n",
    "    ax.set_xlabel('Training points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kooplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
