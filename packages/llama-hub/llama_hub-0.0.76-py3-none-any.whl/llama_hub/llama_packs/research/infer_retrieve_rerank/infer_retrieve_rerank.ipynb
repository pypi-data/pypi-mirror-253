{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8dbce5d-f3e3-4c82-92ee-0f64b83e51bb",
   "metadata": {},
   "source": [
    "# Infer Retrieve Rerank\n",
    "\n",
    "Taken from the paper [\"In-Context Learning for Extreme Multi-Label Classification](https://arxiv.org/pdf/2401.12178.pdf) by Oosterlinck et al."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d245ce-1f4a-45f8-a608-4941c8cb94b8",
   "metadata": {},
   "source": [
    "## Try out a Dataset\n",
    "\n",
    "We use the BioDEX dataset as mentioned in the paper.\n",
    "\n",
    "Here is the [link to the paper](https://arxiv.org/pdf/2305.13395.pdf). Here is the [link to the Github repo](https://github.com/KarelDO/BioDEX)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e62fa4b-7322-4381-9703-c3c090b6eaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1.52k/1.52k [00:00<00:00, 4.14MB/s]\n",
      "Downloading data files:   0%|                                                                                                         | 0/3 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|                                                                                                          | 0.00/202M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:   2%|██                                                                                               | 4.19M/202M [00:02<01:52, 1.76MB/s]\u001b[A\n",
      "Downloading data:   6%|██████                                                                                           | 12.6M/202M [00:03<00:54, 3.50MB/s]\u001b[A\n",
      "Downloading data:  10%|██████████                                                                                       | 21.0M/202M [00:05<00:37, 4.86MB/s]\u001b[A\n",
      "Downloading data:  15%|██████████████                                                                                   | 29.4M/202M [00:06<00:30, 5.63MB/s]\u001b[A\n",
      "Downloading data:  19%|██████████████████▏                                                                              | 37.7M/202M [00:07<00:26, 6.17MB/s]\u001b[A\n",
      "Downloading data:  23%|██████████████████████▏                                                                          | 46.1M/202M [00:08<00:24, 6.49MB/s]\u001b[A\n",
      "Downloading data:  27%|██████████████████████████▏                                                                      | 54.5M/202M [00:09<00:20, 7.28MB/s]\u001b[A\n",
      "Downloading data:  31%|██████████████████████████████▏                                                                  | 62.9M/202M [00:10<00:19, 7.25MB/s]\u001b[A\n",
      "Downloading data:  35%|██████████████████████████████████▎                                                              | 71.3M/202M [00:11<00:18, 6.98MB/s]\u001b[A\n",
      "Downloading data:  39%|██████████████████████████████████████▎                                                          | 79.7M/202M [00:12<00:16, 7.20MB/s]\u001b[A\n",
      "Downloading data:  44%|██████████████████████████████████████████▎                                                      | 88.1M/202M [00:16<00:27, 4.09MB/s]\u001b[A\n",
      "Downloading data:  48%|██████████████████████████████████████████████▎                                                  | 96.5M/202M [00:18<00:22, 4.71MB/s]\u001b[A\n",
      "Downloading data:  52%|██████████████████████████████████████████████████▉                                               | 105M/202M [00:19<00:18, 5.26MB/s]\u001b[A\n",
      "Downloading data:  56%|██████████████████████████████████████████████████████▉                                           | 113M/202M [00:20<00:15, 5.62MB/s]\u001b[A\n",
      "Downloading data:  60%|███████████████████████████████████████████████████████████                                       | 122M/202M [00:21<00:13, 6.11MB/s]\u001b[A\n",
      "Downloading data:  64%|███████████████████████████████████████████████████████████████                                   | 130M/202M [00:22<00:11, 6.40MB/s]\u001b[A\n",
      "Downloading data:  69%|███████████████████████████████████████████████████████████████████▏                              | 138M/202M [00:24<00:09, 6.54MB/s]\u001b[A\n",
      "Downloading data:  73%|███████████████████████████████████████████████████████████████████████▎                          | 147M/202M [00:28<00:14, 3.88MB/s]\u001b[A\n",
      "Downloading data:  77%|███████████████████████████████████████████████████████████████████████████▎                      | 155M/202M [00:29<00:10, 4.53MB/s]\u001b[A\n",
      "Downloading data:  81%|███████████████████████████████████████████████████████████████████████████████▍                  | 164M/202M [00:33<00:11, 3.26MB/s]\u001b[A\n",
      "Downloading data:  85%|███████████████████████████████████████████████████████████████████████████████████▍              | 172M/202M [00:34<00:07, 3.94MB/s]\u001b[A\n",
      "Downloading data:  89%|███████████████████████████████████████████████████████████████████████████████████████▌          | 180M/202M [00:35<00:04, 4.54MB/s]\u001b[A\n",
      "Downloading data:  94%|███████████████████████████████████████████████████████████████████████████████████████████▋      | 189M/202M [00:37<00:02, 5.05MB/s]\u001b[A\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 202M/202M [00:38<00:00, 5.28MB/s]\u001b[A\n",
      "Downloading data files:  33%|████████████████████████████████▎                                                                | 1/3 [00:38<01:16, 38.30s/it]\n",
      "Downloading data:   0%|                                                                                                         | 0.00/51.8M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:   8%|███████▊                                                                                        | 4.19M/51.8M [00:00<00:08, 5.30MB/s]\u001b[A\n",
      "Downloading data:  24%|███████████████████████▎                                                                        | 12.6M/51.8M [00:01<00:04, 9.47MB/s]\u001b[A\n",
      "Downloading data:  41%|██████████████████████████████████████▉                                                         | 21.0M/51.8M [00:02<00:02, 11.1MB/s]\u001b[A\n",
      "Downloading data:  57%|██████████████████████████████████████████████████████▍                                         | 29.4M/51.8M [00:02<00:02, 10.8MB/s]\u001b[A\n",
      "Downloading data:  73%|██████████████████████████████████████████████████████████████████████                          | 37.7M/51.8M [00:03<00:01, 11.0MB/s]\u001b[A\n",
      "Downloading data:  89%|█████████████████████████████████████████████████████████████████████████████████████▌          | 46.1M/51.8M [00:04<00:00, 11.5MB/s]\u001b[A\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 51.8M/51.8M [00:04<00:00, 10.9MB/s]\u001b[A\n",
      "Downloading data files:  67%|████████████████████████████████████████████████████████████████▋                                | 2/3 [00:43<00:18, 18.57s/it]\n",
      "Downloading data:   0%|                                                                                                         | 0.00/83.9M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:   5%|████▊                                                                                           | 4.19M/83.9M [00:01<00:26, 2.97MB/s]\u001b[A\n",
      "Downloading data:  15%|██████████████▍                                                                                 | 12.6M/83.9M [00:02<00:14, 4.83MB/s]\u001b[A\n",
      "Downloading data:  25%|███████████████████████▉                                                                        | 21.0M/83.9M [00:03<00:10, 5.88MB/s]\u001b[A\n",
      "Downloading data:  35%|█████████████████████████████████▌                                                              | 29.4M/83.9M [00:05<00:08, 6.49MB/s]\u001b[A\n",
      "Downloading data:  45%|███████████████████████████████████████████▏                                                    | 37.7M/83.9M [00:05<00:05, 7.89MB/s]\u001b[A\n",
      "Downloading data:  55%|████████████████████████████████████████████████████▊                                           | 46.1M/83.9M [00:06<00:04, 7.60MB/s]\u001b[A\n",
      "Downloading data:  65%|██████████████████████████████████████████████████████████████▎                                 | 54.5M/83.9M [00:07<00:03, 7.98MB/s]\u001b[A\n",
      "Downloading data:  75%|███████████████████████████████████████████████████████████████████████▉                        | 62.9M/83.9M [00:08<00:02, 9.09MB/s]\u001b[A\n",
      "Downloading data:  85%|█████████████████████████████████████████████████████████████████████████████████▌              | 71.3M/83.9M [00:09<00:01, 9.82MB/s]\u001b[A\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 83.9M/83.9M [00:09<00:00, 8.50MB/s]\u001b[A\n",
      "Downloading data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:52<00:00, 17.65s/it]\n",
      "Extracting data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 711.22it/s]\n",
      "Generating train split: 100%|█████████████████████████████████████████████████████████████████████████████████| 9624/9624 [00:00<00:00, 14335.27 examples/s]\n",
      "Generating validation split: 100%|████████████████████████████████████████████████████████████████████████████| 2407/2407 [00:00<00:00, 20853.95 examples/s]\n",
      "Generating test split: 100%|██████████████████████████████████████████████████████████████████████████████████| 3628/3628 [00:00<00:00, 19338.73 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# dataset = datasets.load_dataset(\"BioDEX/raw_dataset\")\n",
    "import datasets\n",
    "\n",
    "# load the report-extraction dataset\n",
    "dataset = datasets.load_dataset(\"BioDEX/BioDEX-ICSR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f0ea579-f534-42de-b7d9-79f7260dda2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'abstract', 'fulltext', 'target', 'pmid', 'fulltext_license', 'title_normalized', 'issue', 'pages', 'journal', 'authors', 'pubdate', 'doi', 'affiliations', 'medline_ta', 'nlm_unique_id', 'issn_linking', 'country', 'mesh_terms', 'publication_types', 'chemical_list', 'keywords', 'references', 'delete', 'pmc', 'other_id', 'safetyreportid', 'fulltext_processed'],\n",
       "        num_rows: 9624\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'abstract', 'fulltext', 'target', 'pmid', 'fulltext_license', 'title_normalized', 'issue', 'pages', 'journal', 'authors', 'pubdate', 'doi', 'affiliations', 'medline_ta', 'nlm_unique_id', 'issn_linking', 'country', 'mesh_terms', 'publication_types', 'chemical_list', 'keywords', 'references', 'delete', 'pmc', 'other_id', 'safetyreportid', 'fulltext_processed'],\n",
       "        num_rows: 2407\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'abstract', 'fulltext', 'target', 'pmid', 'fulltext_license', 'title_normalized', 'issue', 'pages', 'journal', 'authors', 'pubdate', 'doi', 'affiliations', 'medline_ta', 'nlm_unique_id', 'issn_linking', 'country', 'mesh_terms', 'publication_types', 'chemical_list', 'keywords', 'references', 'delete', 'pmc', 'other_id', 'safetyreportid', 'fulltext_processed'],\n",
       "        num_rows: 3628\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cecfa23d-f263-44e3-bd07-7aa0ccbc2c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import get_tokenizer\n",
    "import re\n",
    "from typing import Set\n",
    "\n",
    "tokenizer = get_tokenizer()\n",
    "\n",
    "\n",
    "sample_size = 5\n",
    "\n",
    "def get_reactions_row(raw_target: str) -> List[str]:\n",
    "    \"\"\"Get reactions from a single row.\"\"\"\n",
    "    reaction_pattern = re.compile(r\"reactions:\\s*(.*)\")\n",
    "    reaction_match = reaction_pattern.search(raw_target)\n",
    "    if reaction_match:\n",
    "        reactions = reaction_match.group(1).split(\",\")\n",
    "        reactions = [r.strip().lower() for r in reactions]\n",
    "    else:\n",
    "        reactions = []\n",
    "    return reactions\n",
    "\n",
    "\n",
    "def get_reactions_set(dataset) -> Set[str]:\n",
    "    \"\"\"Get set of all reactions.\"\"\"\n",
    "    reactions = set()\n",
    "    for data in dataset[\"train\"]:\n",
    "        reactions.update(set(get_reactions_row(data[\"target\"])))\n",
    "    return reactions\n",
    "\n",
    "\n",
    "def get_samples(dataset, sample_size: int = 5):\n",
    "    \"\"\"Get processed sample.\n",
    "\n",
    "    Contains source text and also the reaction label.\n",
    "\n",
    "    Parse reaction text to specifically extract reactions.\n",
    "    \n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    for idx, data in enumerate(dataset[\"train\"]):\n",
    "        if idx >= sample_size:\n",
    "            break\n",
    "        text = data[\"fulltext_processed\"]\n",
    "        raw_target = data[\"target\"]\n",
    "\n",
    "        reactions = get_reactions_row(raw_target)\n",
    "\n",
    "        samples.append({\n",
    "            \"text\": text,\n",
    "            \"reactions\": reactions\n",
    "        })\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aca770f-8a51-4206-a11c-dc59b1b90a1c",
   "metadata": {},
   "source": [
    "### Index each Reaction with a Vector Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c6f7ffea-d698-4fee-8609-92326a0bb7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1r/c3h91d9s49xblwfvz79s78_c0000gn/T/ipykernel_29743/1748569963.py:4: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  random.sample(all_reactions, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fixed eruption',\n",
       " 'abdominal compartment syndrome',\n",
       " 'foreign body reaction',\n",
       " 'intermittent claudication',\n",
       " 'chorioretinal disorder']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "all_reactions = get_reactions_set(dataset)\n",
    "random.sample(all_reactions, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4c15f5ce-eb3c-4776-b7ad-47f0e08f06de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.schema import TextNode\n",
    "from llama_index.embeddings import OpenAIEmbedding\n",
    "from llama_index.ingestion import IngestionPipeline\n",
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "reaction_nodes = [TextNode(text=r) for r in all_reactions]\n",
    "pipeline = IngestionPipeline(transformations=[OpenAIEmbedding()])\n",
    "reaction_nodes = await pipeline.arun(documents=reaction_nodes)\n",
    "\n",
    "index = VectorStoreIndex(reaction_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d3314e-06e7-46aa-aa70-cd726238cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction_nodes[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2a9a312d-8197-429e-a766-55edcbcb56fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction_retriever = index.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "62d5f304-4e42-491d-a81e-c3a8c47e008f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='e6412990-2c03-40d1-bdb9-586e349b1293', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='abdominal pain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.9158768529615556),\n",
       " NodeWithScore(node=TextNode(id_='cf067b02-9418-4588-8f98-6d91f91499b4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='abdominal symptom', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.9104600840524487)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reaction_retriever.retrieve('abdominal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a6a677-8306-4b8f-b009-3a1992e9ad22",
   "metadata": {},
   "source": [
    "## Define Infer-Retrieve-Rerank Pipeline\n",
    "\n",
    "Here we define the core components needed for the infer-retrieve-rerank pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2790e307-7e48-4f6b-ac30-ca261c98a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers import BaseRetriever\n",
    "from llama_index.llms.llm import LLM\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.prompts import PromptTemplate\n",
    "from llama_index.query_pipeline import QueryPipeline\n",
    "from llama_index.postprocessor.types import BaseNodePostprocessor\n",
    "from llama_index.postprocessor.rankGPT_rerank import RankGPTRerank\n",
    "from llama_index.output_parsers import ChainableOutputParser\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b94016bc-8af6-4714-b713-1662ec127c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_prompt_str = \"\"\"\\\n",
    "\n",
    "Your job is to output a list of predictions given context from a given piece of text. The text context,\n",
    "and information regarding the set of valid predictions is given below. \n",
    "\n",
    "Return the predictions as a comma-separated list of strings.\n",
    "\n",
    "Text Context:\n",
    "{doc_context}\n",
    "\n",
    "Prediction Info:\n",
    "{pred_context}\n",
    "\n",
    "Predictions: \"\"\"\n",
    "\n",
    "infer_prompt = PromptTemplate(infer_prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3589b9e6-cfb5-4c60-800d-923ea042bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredsOutputParser(ChainableOutputParser):\n",
    "    \"\"\"Predictions output parser.\"\"\"\n",
    "\n",
    "    def parse(self, output: str) -> List[str]:\n",
    "        \"\"\"Parse predictions.\"\"\"\n",
    "        tokens = output.split(\",\")\n",
    "        return [t.strip() for t in tokens]\n",
    "\n",
    "preds_output_parser = PredsOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3b29811f-356e-433d-a159-ebc711d5f5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_str = \"\"\"\\\n",
    "Given a piece of text, rank the {num} passages above based on their relevance \\\n",
    "to this piece of text. The passages \\\n",
    "should be listed in descending order using identifiers. \\\n",
    "The most relevant passages should be listed first. \\\n",
    "The output format should be [] > [], e.g., [1] > [2]. \\\n",
    "Only response the ranking results, \\\n",
    "do not say any word or explain. \\\n",
    "\n",
    "Here is a given piece of text: {query}. \n",
    "\n",
    "\"\"\"\n",
    "rerank_prompt = PromptTemplate(rerank_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b4c9a4ce-28d8-4bc1-a4f6-335328c7c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_retrieve_rerank(\n",
    "    query: str,\n",
    "    retriever: BaseRetriever,\n",
    "    llm: LLM,\n",
    "    pred_context: str,\n",
    "    reranker_top_n: int = 3\n",
    "):\n",
    "    \"\"\"Infer retrieve rerank.\"\"\"\n",
    "    infer_prompt_c = infer_prompt.as_query_component(\n",
    "        partial={\"pred_context\": pred_context}\n",
    "    )\n",
    "    infer_pipeline = QueryPipeline(chain=[infer_prompt_c, llm, preds_output_parser])\n",
    "    preds = infer_pipeline.run(query)\n",
    "\n",
    "    print(f\"PREDS: {preds}\")\n",
    "    all_nodes = []\n",
    "    for pred in preds:\n",
    "        nodes = retriever.retrieve(str(pred))\n",
    "        all_nodes.extend(nodes)\n",
    "\n",
    "    reranker = RankGPTRerank(\n",
    "        llm=llm,\n",
    "        top_n=reranker_top_n,\n",
    "        rankgpt_rerank_prompt=rerank_prompt,\n",
    "        # verbose=True,\n",
    "    )\n",
    "    reranked_nodes = reranker.postprocess_nodes(all_nodes, query_str=query)\n",
    "    return [n.get_content() for n in reranked_nodes]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ea0639-b929-4754-a836-6199e36b970d",
   "metadata": {},
   "source": [
    "### Run Over Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "35269968-d98a-4e77-a320-536f146e58ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = get_samples(dataset, sample_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1e7498f3-6adc-4200-8b12-76cd7939cc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "PREDS: ['fluid overload', 'acute respiratory distress syndrome', 'anxiety', 'delirium', 'myocardial insufficiency', 'hypervolemia', 'hypovolemia', 'pneumonia', 'pleural effusion', 'heart failure', 'respiratory distress', 'allergic reaction', 'eosinophilia', 'diarrhea', 'rash']\n",
      "After Reranking, new rank list for nodes: [0, 2, 20, 18, 9, 10, 8, 16, 14, 26, 27, 24, 25, 29, 28, 6, 7, 4, 5, 12, 11, 13, 1, 3, 21, 22, 23, 15, 17, 19]"
     ]
    }
   ],
   "source": [
    "reaction_retriever = index.as_retriever(similarity_top_k=2)\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-16k\")\n",
    "pred_context = \"\"\"\\\n",
    "The output predictins should be a list of comma-separated adverse \\\n",
    "drug reactions. \\\n",
    "\"\"\"\n",
    "\n",
    "reranker_top_n = 10\n",
    "\n",
    "pred_reactions = []\n",
    "gt_reactions = []\n",
    "for idx, sample in enumerate(samples):\n",
    "    print(idx)\n",
    "    cur_pred_reactions = infer_retrieve_rerank(\n",
    "        sample[\"text\"],\n",
    "        reaction_retriever,\n",
    "        llm,\n",
    "        pred_context,\n",
    "        reranker_top_n=reranker_top_n\n",
    "    )\n",
    "    cur_gt_reactions = sample[\"reactions\"]\n",
    "\n",
    "    pred_reactions.append(cur_pred_reactions)\n",
    "    gt_reactions.append(cur_gt_reactions)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4717069f-19d0-43aa-afeb-e0cb17cb1d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fluid overload',\n",
       " 'acute respiratory distress syndrome',\n",
       " 'respiratory distress',\n",
       " 'cardiac failure',\n",
       " 'myocardial infarction',\n",
       " 'hypervolaemia',\n",
       " 'cardiovascular insufficiency',\n",
       " 'pleural effusion',\n",
       " 'pneumonia',\n",
       " 'diarrhoea']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_reactions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5223f8e2-c08b-459d-9ded-b25b90899616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diarrhoea', 'drug hypersensitivity', 'rash']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_reactions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c81ec8-7b00-4cf7-899f-d0d812a57c50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_hub",
   "language": "python",
   "name": "llama_hub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
