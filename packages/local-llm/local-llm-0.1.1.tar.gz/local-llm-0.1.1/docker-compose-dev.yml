version: '3.8'

services:
  local-llm:
    image: ghcr.io/josh-xt/local-llm:cpu-dev
    environment:
      - LOCAL_LLM_API_KEY=${LOCAL_LLM_API_KEY-}
      - GPU_LAYERS=${GPU_LAYERS-0}
      - MAIN_GPU=${MAIN_GPU-0}
      - DEFAULT_MODEL=${DEFAULT_MODEL-phi-2-dpo}
      - WHISPER_MODEL=${WHISPER_MODEL-base.en}
      - CMAKE_ARGS="-DLLAMA_CUBLAS=on"
      - LLAMA_CUBLAS=1
      - CUDA_DOCKER_ARCH=all
    restart: unless-stopped
    ports:
      - "8091:8091"
    volumes:
      - ./models:/app/models
      - ./outputs:/app/outputs
      - ./voices:/app/voices
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
