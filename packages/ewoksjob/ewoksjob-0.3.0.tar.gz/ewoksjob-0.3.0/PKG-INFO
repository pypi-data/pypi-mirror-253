Metadata-Version: 2.1
Name: ewoksjob
Version: 0.3.0
Summary: Asynchronous and distributed scheduling of Ewoks workflows from python
Home-page: https://gitlab.esrf.fr/workflow/ewoks/ewoksjob/
Author: ESRF
Author-email: wout.de_nolf@esrf.fr
License: MIT
Project-URL: Source, https://gitlab.esrf.fr/workflow/ewoks/ewoksjob/
Project-URL: Documentation, https://ewoksjob.readthedocs.io/
Project-URL: Tracker, https://gitlab.esrf.fr/workflow/ewoks/ewoksjob/issues/
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Requires-Python: >=3.6
Description-Content-Type: text/markdown
Provides-Extra: worker
Provides-Extra: redis
Provides-Extra: sql
Provides-Extra: monitor
Provides-Extra: slurm
Provides-Extra: beacon
Provides-Extra: blissworker
Provides-Extra: test
Provides-Extra: dev
Provides-Extra: doc
License-File: LICENSE.md

# ewoksjob

Utilities for job scheduling of [ewoks](https://ewoks.readthedocs.io/) workflows.

Ewoksjob provides an ewoks interface for asynchronous and distributed scheduling of [ewoks](https://ewoks.readthedocs.io/) from python.

Note that *ewoksjob* distributes the execution of workflows while [ewoksdask](https://ewoks.readthedocs.io/)
distributes the execution of tasks in a workflow. So in the context of workflows, job scheduling exists on two levels.

The primary clients that need to schedule workflows are
* [Ewoksserver](https://gitlab.esrf.fr/workflow/ewoks/ewoksserver): web backend for ewoks.
* [Bliss](https://gitlab.esrf.fr/bliss/bliss): the ESRF beamline control system.
* [Daiquiri](https://gitlab.esrf.fr/ui/daiquiri): web backend for Bliss.

## Installation

Install on the client side

```bash
pip install ewoksjob
```

Install on the worker side

```bash
pip install ewoksjob[worker]
```

## Getting started

Start a worker pool that can execute ewoks graphs

```bash
ewoksjob worker
```

Start a workflow on the client side

```python
from ewoksjob.client import submit

workflow = {"graph": {"id": "mygraph"}}
future = submit(args=(workflow,))
result = future.get()
```

Note that both environments need to be able to import `celeryconfig` which
contains celery configuration (mainly the message broker and result backend URL's).

## Hello world example

Clone the git repository and start a worker pool

```bash
scripts/worker.sh --sql
```

Submit workflows

```bash
scripts/runjobs.sh --sql
```

## Tests

```bash
pytest --pyargs ewoksjob
```

To run the redis tests you need `redis-server` (e.g. `conda install redis-server`).

## Documentation

https://ewoksjob.readthedocs.io/
