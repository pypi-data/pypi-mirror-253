# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/2A. CLARA.ipynb.

# %% auto 0
__all__ = []

# %% ../nbs/2A. CLARA.ipynb 4
import os
import io
import time
import torch
import torchaudio

# %% ../nbs/2A. CLARA.ipynb 5
from pathlib import Path
import json
from fastprogress import progress_bar, master_bar
import numpy as np
import random

from torch import nn
import torch.nn.functional as F
from torch.utils.data.dataloader import DataLoader

from fastcore.script import *

from . import vad, utils, wh_transcribe, vq_stoks
import webdataset as wds
from huggingface_hub import hf_hub_download

from clara.datamodule.utils import get_log_melspec
import clara
import torch.nn.functional as F

import whisper

# %% ../nbs/2A. CLARA.ipynb 8
def calc_len(x):
    x['seconds'] = torch.tensor(x['tend'] - x['tstart'])
    return x

def chunked_dataset(input, key, bs=16, num_workers=1, shuffle=False):
    shards = utils.shard_glob(input)
    rename_files = vad.fix_dots_in_names if 'librilight' in shards[0] else None
    ds = vad.load_dataset(shards, rename_files=rename_files).compose(
        vq_stoks.merge_in(vq_stoks.derived_dataset(Path(shards[0]).parent, "vad", key=key)),
#         wh_transcribe.merge_in(wds.WebDataset(str(p.parent/vad.flac_to_vad_name(input, key))).decode()),
        lambda x: wh_transcribe.split_to_chunks(x, pad_to_seconds=15),
        utils.resampler(16000, 'samples_16k'),
        wds.map(calc_len),
        wds.to_tuple('__key__', 'samples_16k', 'seconds'),
#         wds.shuffle(6000),
        wds.batched(1 if shuffle else bs),
    )
    dl = wds.WebLoader(ds, num_workers=min(len(shards), num_workers), batch_size=None)
    if shuffle: dl = dl.unbatched().batched(bs)
    return dl

# %% ../nbs/2A. CLARA.ipynb 26
def flac_to_spk_emb_name(input, key='raw'):
    return input.rsplit("/", 1)[1].replace(key, f'spk_emb') + ".gz"

@call_parse
def process_shard(
    input:str,          # input shard URL/path
    output:str=None,    # output shard URL/path
    bs:int=None,        # batch size (16 uses around 11GB of VRAM)
    n_samples:int=None, # limit the number of samples (useful for quick benchmarking)
    key:str='flac',
):
    if output is None: output = flac_to_spk_emb_name(input, key)
    if bs is None: bs = 16
    if n_samples is None: n_samples = 'noinfer'
    else: n_samples = n_samples // bs

    dl = chunked_dataset(input, key, bs=bs)
    
    model = clara.PLCLARA.load_from_checkpoint(hf_hub_download('knoriy/CLARA', 'clara-medium.ckpt'), map_location='cuda')
    
    tmp = output+".tmp"
    with wds.TarWriter(tmp) as sink:
        for keys, samples, seconds in progress_bar(dl, total=n_samples):
            with torch.no_grad():
                mels = torch.stack([get_log_melspec(sample.numpy(), 16000) for sample in samples])
                audio_features = model.encode_audio(mels.permute(0,2,1).cuda())
                audio_features = F.normalize(audio_features, dim=-1)
                audio_features = model.model.audio_transform(audio_features)
            for key, emb in zip(keys, embs):
                sink.write({
                    "__key__": key,
                    "spk_emb.npy": audio_features.cpu().numpy(),
                })
    os.rename(tmp, output)
