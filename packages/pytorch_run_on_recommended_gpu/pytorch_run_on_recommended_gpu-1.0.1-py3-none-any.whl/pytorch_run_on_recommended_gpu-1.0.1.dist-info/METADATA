Metadata-Version: 2.1
Name: pytorch-run-on-recommended-gpu
Version: 1.0.1
Summary: A lightweight scheduler reading nvidia-smi and updating torch environment variables to run on the recommended GPU.
License: GPL-3.0-or-later
Author: Christian Weihsbach
Author-email: christian.weihsbach@uni-luebeck.de
Requires-Python: >=3.9,<4.0
Classifier: License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Dist: paramiko
Requires-Dist: tabulate
Requires-Dist: torch
Description-Content-Type: text/markdown

# pytorch_run_on_recommended_gpu

A lightweight script that interactively updates `CUDA_VISIBLE_DEVICES` for pytorch
## Install

`pip install pytorch_run_on_recommended_cuda`

## Usage from CLI

Perform a dry run

`pytorch_run_on_recommended_cuda`


Run a script and select a GPU manually

`pytorch_run_on_recommended_cuda`



Run a script from the next available GPU

`pytorch_run_on_recommended_cuda --select * <path_to_script>`


Run a script from the next two available GPUs

`pytorch_run_on_recommended_cuda --select ** <path_to_script>`


Run a script from GPU ids 6 and 7

`pytorch_run_on_recommended_cuda --select 6 7 <path_to_script>`


## Usage from .py file
```python
import os
from pytorch.run_on_recommended_gpu.run_on_recommended_gpu import get_cuda_environ_vars as get_vars

os.environ.update(get_vars('*'))
import torch # Import torch after you have updated the vars.
```
