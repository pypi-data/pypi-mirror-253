{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an SNN with fewer synops\n",
    "Similar as in the previous tutorial, we start by defining a spiking model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sinabs\n",
    "import sinabs.layers as sl\n",
    "\n",
    "class SNN(nn.Sequential):\n",
    "    def __init__(self, batch_size):\n",
    "        super().__init__(\n",
    "            sl.FlattenTime(),\n",
    "            nn.Conv2d(1, 16, 5, bias=False),\n",
    "            sl.IAFSqueeze(batch_size=batch_size),\n",
    "            sl.SumPool2d(2),\n",
    "            nn.Conv2d(16, 32, 5, bias=False),\n",
    "            sl.IAFSqueeze(batch_size=batch_size),\n",
    "            sl.SumPool2d(2),\n",
    "            nn.Conv2d(32, 120, 4, bias=False),\n",
    "            sl.IAFSqueeze(batch_size=batch_size),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(120, 10, bias=False),\n",
    "            sl.IAFSqueeze(batch_size=batch_size),\n",
    "            sl.UnflattenTime(batch_size=batch_size),\n",
    "        )\n",
    "\n",
    "batch_size = 5\n",
    "snn = SNN(batch_size=batch_size)\n",
    "snn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SNNAnalyzer` class tracks different statistics for spiking (such as IAF/LIF) and parameter (such as Conv2d/Linear) layers. The number of synaptic operations is part of the parameter layers. If we attach such an analyzer to the model, we'll be able to use layer- or model-wide statistics during training, for optimization or logging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = sinabs.SNNAnalyzer(snn)\n",
    "print(f\"Synops before feeding input: {analyzer.get_model_statistics()['synops']}\")\n",
    "\n",
    "rand_input_spikes = (torch.ones((batch_size, 10, 1, 28, 28)) ).float()\n",
    "y_hat = snn(rand_input_spikes)\n",
    "print(f\"Synops after feeding input: {analyzer.get_model_statistics()['synops']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can break down the statistics for each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_stats = analyzer.get_layer_statistics()\n",
    "\n",
    "for layer_name in layer_stats.keys():\n",
    "    print(f\"Layer {layer_name} tracks statistics {layer_stats[layer_name].keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we can calculate the total number synops, we might want to choose a target synops number as part of our objective function. If we set the number to low, the network will fail to learn anything as there won't be any activity at all. As a rule of thumb, do a training run without adding synops to your loss at first and observe how the numbers evolve. You can then set a target synops number accordingly. \n",
    "\n",
    "In this tutorial we're going to only optimise for number of synaptic operations given a constant input. We set the target to twice the number of operations of the untrained network. We log the number of synops over time and also the average firing rate in the network, which is closely related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the target number of operations\n",
    "target_synops = 2 * analyzer.get_model_statistics()['synops'].detach_()\n",
    "\n",
    "optim = torch.optim.Adam(snn.parameters(), lr=1e-3)\n",
    "\n",
    "n_synops = []\n",
    "firing_rates = []\n",
    "for epoch in range(100):\n",
    "    sinabs.reset_states(snn)\n",
    "    sinabs.zero_grad(snn)\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    snn(rand_input_spikes)\n",
    "\n",
    "    model_stats = analyzer.get_model_statistics()\n",
    "    synops = model_stats['synops']\n",
    "    firing_rate = model_stats['firing_rate']\n",
    "    \n",
    "    n_synops.append(synops.detach().cpu().numpy())\n",
    "    firing_rates.append(firing_rate.detach().cpu().numpy())\n",
    "    \n",
    "    synops_loss = (target_synops - synops).square() / target_synops.square()\n",
    "    synops_loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "ax1.plot(n_synops, label=\"Synops during training\")\n",
    "ax1.axhline(y=target_synops.item(), color='black', label=\"Target synops\")\n",
    "ax1.set_ylabel(\"Synaptic ops\\nper mini-batch\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(firing_rates)\n",
    "ax2.set_ylabel(\"Average firing rate\\nacross all neurons\")\n",
    "ax2.set_xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Adam optimizer, which uses a form of momentum, we can see that the network quickly optimizes for the target number of synaptic operations. Closely related (although always between 0 and 1) is the average firing rate for all neurons. Additionally, we can also plot some statistics for each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_stats = analyzer.get_layer_statistics()\n",
    "\n",
    "for layer_name in ['2', '5', '8', '11']:\n",
    "    print(f\"Layer {layer_name} has {layer_stats['spiking'][layer_name]['n_neurons']} neurons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 1, sharex=True, figsize=(6,6))\n",
    "\n",
    "for axis, layer_name in zip(axes, ['2', '5', '8', '11']):\n",
    "    axis.hist(layer_stats['spiking'][layer_name]['firing_rate_per_neuron'].detach().numpy().ravel(), bins=10)\n",
    "    axis.set_ylabel(f\"Layer {layer_name}\")\n",
    "axes[0].set_title(\"Histogram of firing rates\")\n",
    "axes[-1].set_xlabel(\"Spikes / neuron / time step\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c00e5e7c7a569083cb991dfa106f557879cc0d1d84bf5b9d92fbb6bf680d358"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
